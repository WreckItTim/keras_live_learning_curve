import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.preprocessing import OneHotEncoder

from IPython.display import clear_output
import matplotlib.pyplot as plt
class learning_curve(tf.keras.callbacks.Callback):
    def __init__(self, track_metric='loss'):
        self.track_metric = track_metric
        self.epochs = []
        self.losses = []
    def on_epoch_end(self, epoch, logs=None):
        clear_output(wait=True)
        self.epochs.append(len(self.epochs))
        self.losses.append(logs.get(self.track_metric))
        plt.plot(self.epochs, self.losses)
        plt.title('Learning Curve')
        plt.xlabel('Epoch')
        plt.ylabel(self.track_metric)
        plt.show()

# load iris toy dataset
data = load_iris()
X, Y = data['data'], data['target']

# one hot encode
Y = OneHotEncoder(sparse=False).fit_transform(Y.reshape([-1, 1]))

# create simple model
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(3))
model.compile(loss='mean_squared_error', optimizer='adam')
history = model.fit(X, Y,
                    epochs=100,
                    callbacks=[learning_curve('loss')], 
                    verbose=0,
                   )
